# ğŸ’» Software Intro ğŸ’»

Here's how you can control the robot and make it intelligent:

### ğŸ•¹ï¸ Basic Control

- **Joint** (motor angle) control â†’ leader-follower arm control
- **End effector pose** control â†’ VR remote control

```{note}
For the first version, we focus primarily on the hardware. The LeRobot code remains unmodified. You can recreate Demo 0.1.0 by connecting one arm to the RaspberryPi and the other to the desktop for remote control. The LeRobot code for XLeRobot will be updated soon as our top priority.
```

### ğŸ§  Paths towards General Embodied Machine Intelligence (TODO)

### ğŸ”ˆAdvertisment:

- **Our lab**: [Rice RobotPI Lab](https://robotpilab.github.io/)
    - Our vision includes using [**Caging in Time**](https://robotpilab.github.io/publication/caging/) and **Funnel-based Manipulation** methods to achieve robust object manipulation in imperfect real-world conditions â€” including perception noise, network lag, and [contact rich](https://robotpilab.github.io/publication/collision-inclusive-manipulation/) environments.
- **Simulation platform** (my personal preference): [Maniskill](https://www.maniskill.ai/)
    - ğŸš€Fast GPU acceleration for parallel simulations
    - ğŸ¨Beautiful photorealistic visuals through ray-tracing
    - ğŸª¶Lightweight, consistent, and user-friendly (compared to Isaac Lab, in my opinion)
    - ğŸ¤–Support for [multiple robots](https://maniskill.readthedocs.io/en/latest/robots/index.html) (including [SO100 arm](https://x.com/Stone_Tao/status/1910101218241978537))
    ![image](https://github.com/user-attachments/assets/03008e8c-edbc-43c9-bbe7-13866c436a73)
        
